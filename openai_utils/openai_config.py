import os
from dataclasses import dataclass, field
from typing import Optional, Dict, Any


@dataclass
class OpenAiConfig:
    """
    Class for managing OpenAI configuration.
    """

    RETRY_API_KEY: Optional[str] = os.getenv("OPENAI_RETRY_API_KEY")

    api_key: str = os.getenv("OPENAI_API_KEY")
    organization: str = os.getenv("OPENAI_ORGANIZATION")
    additional_config: Dict[str, str] = field(default_factory=dict)

    @property
    def config(self) -> Dict[str, str]:
        config_dict = {
            'api_key': self.api_key,
            'organization': self.organization,
            **self.additional_config,
        }
        return {key: value for key, value in config_dict.items() if value is not None}

    def create_retry_config(self, retry_api_key: Optional[str] = None, **retry_kwargs) -> Dict[str, str]:
        """
        Create a retry configuration based on the current configuration.
        """
        retry_config = {
            'api_key': retry_api_key or self.RETRY_API_KEY,
            'organization': self.organization,
            **retry_kwargs,
        }
        return {key: value for key, value in retry_config.items() if value is not None}


@dataclass
class OpenAiOptions:
    """
    Class for managing OpenAI chat completion options.

    Note on max_tokens: The maximum number of tokens that can be generated by the model in the output (ie. the
    completion message requested max). Ex) If ~5000 tokens in system and user message, then we expect a max of 2000
    tokens in the response. GPT-4 limit is 8192 total. Please note that very long outputs are more likely to be cut off.

    Parameters:
    - model: The language model to use (default: 'gpt-4').
    - max_tokens: The maximum number of tokens in the generated output (default: 3000).
    - temperature: Controls the randomness of the output (default: 0).
    - log_response: Whether to log the response (default: False).
    - kwargs: Additional options.
    """

    model: str = 'gpt-4'
    max_tokens: int = 3000
    temperature: float = 0.0
    log_response: bool = False
    additional_options: Dict[str, Any] = field(default_factory=dict)

    def options(self) -> Dict[str, Any]:
        return {
            'model': self.model,
            'max_tokens': self.max_tokens,
            'temperature': self.temperature,
            'log_response': self.log_response,
            **self.additional_options,
        }
